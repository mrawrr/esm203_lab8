---
title: "esm203_lab8"
author: "Meghna Rao"
date: "11/15/2021"
output: html_document
---

```{r setup, include=FALSE, message = FALSE, warning = FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)

# Attach Packages
library(tidyverse)
library(corrplot)
library(stargazer)
library(broom)
library(modelsummary)
library(here)
```

```{r}
homes <- read.csv(here("slo_homes.csv"))
```
## Make a subset called `home_sub` that only contains observations (rows) where the city is:
- San Luis Obispo
- Arroyo Grande
- Atascadero
- Santa Maria-orcutt

use filter to keep or exclude rows within the column `City`
- DO NOT TYPE LIKE THIS `filter(City == c("San Luis Obispo", "Arroyo Grande", "Atascadero", "Santa Maria-Orcutt"))` because it chooses and selects things based on position. Tells it to look in each row in city column for each row to match the order here!

- we want to look in every row and see if any of these options show up in any of the rows! so use `%in%`
```{r}
home_sub <- homes %>% 
  filter(City %in% c("San Luis Obispo", "Arroyo Grande", "Atascadero", "Santa Maria-Orcutt"))
```

## check your data with `unique`
I want to check `home_sub` to see what the observations are in a column.
type in `unique(homes_sub$City)`

## Find summary statistics 

For home pric e based on city and sale status
- find and return in a nice summary table the mean and st deviation of home price, grouped by city and sale status

```{r}
summary_table <- home_sub %>% 
  group_by(City, Status) %>% 
  summarize(mean_price = mean(Price, na.rm = TRUE), #na.rm = TRUE will sure the NA values are removed
            sd_price = sd(Price, na.rm = TRUE))
```
you can add `include = FALSE` into the knittr for this code chunk so the code doesnt show
if you don't even want the code to run add `eval = FALSE` into the code knitrr


## Look at data
HOw do these values compared based on different grouping variables
forclosure prices are less than regular prices. 
how does housing prices compare across different states
SLO has higher mean home prices than Arroyo Grande which has higher mean home prices than atascadero
we would want to do this for many different variables to assess how different they are from eachother. 

## Exploratory graph

```{r}
ggplot(data = home_sub, aes(x = Price)) +
  geom_density(aes(color = City, fill = City), alpha = 0.3) + # fill color and line color. color and fill are within aes (because things within aes relates to a varibale. maps varible onto an aesthetic. if its refereing to a constant, outside aes) 
# here alpha is set to a transparecny constant of 0.3, so it is outside the aes
  scale_x_continuous(limits = c(0, 3e6)) # changes the scale of the x axis. set limits of two endpoints within a vector
```

## Explore the relationship with visual data exploration between square footage and home price

Change the point color by city and the point shape by sale status

```{r, eval = FALSE}
ggplot(data = home_sub, aes(x = SqFt, y = Price)) +
  geom_point() + # looks like a positive linear correlation between positive correlation and home price. There is some variation in expected home prices
  geom_smooth(method = lm) # it says use the linear lm
# looks like a positive linear correlation between positive correlation and home price. There is some variation in expected home prices

```
There is an outlier! This data does not tell you the location of the house, so tiny homes on the ocean could be highly priced because of the location. Other reasons could be that its a small home on a big property, etc. Why does this point diverge quite a bit from what our model should be?


```{r}
ggplot(data = home_sub, aes(x = SqFt, y = Price)) +
  geom_point(aes(color = City, shape = Status)) +
  geom_smooth(method = lm)
```

## Model the relationship with home prices as DV

`homes_lm1 <- lm(Price ~ City + Bedrooms + Bathrooms + SqFt + PricePerSqFt + Status, data = home_sub)`

- ohh girl be careful with this! price per squarefoot is a redudant variable to include in this data set

```{r}
homes_lm1 <- lm(Price ~ City + Bedrooms + Bathrooms + SqFt + PricePerSqFt + Status, data = home_sub) # gen linear regression model

#Make a subset that only contains the quantitative varibales
homes_quant <- home_sub %>% 
  select(Price:PricePerSqFt) # gives us a version of the home_sub that only contains quantitative varibles to take out categorical varibales

homes_cor <- cor(homes_quant)
homes_cor  # looking at correltiaon, anything close toa 1 like a 0.7 shows a strong positive correlation ex bathrooms and bedrooms and strongly/moderatley highly positively correlated values 

corrplot(homes_cor, method = 'ellipse')

# return the linear regression model by typing homes_lm1 in the console
# the reference level for home is arroyo grand. So how to interpret categorical reference levels relative to the reference level (see lecture notes)
# how to interpret the bedroom (numerical varible) - if everything else is the same, thats the average price decrease for every one increase in bedrooms - PROBLEM why is there a 
# for each add 1 sq footage of the home, expect the aveage price of the house to increase by this much
# for status, ref level is forclosure RED FLAG - model says that regular sale has lower prices than those in foreclosure.
# be very concerned! what seems redudundant!!
```

## How would i explore the diagnostic plots for this??

`plot(homes_lm1)`

```{r}
plot(homes_lm1)
# look at cooks distance. the measured shows that cooks distance of 0.5 and 1 is pulling a lot of weight. It is waay outside of what we would expect. also not the only place this shows up.(this is the residuals v. leverage plot). Outliers show up in scatter plot and in residuals v. leverage 
```
## try another model

simplify the model a bit by only including the varibales for 
- city
- Sqft
- Status

```{r}
homes_lm2 <- lm(Price ~ City + SqFt + Status, data = home_sub) # created a new linear model where home price is a function of city and sqft and status. and data comes from home_sub
```

We see that now, compared to a ref level of arroyo grande, SLO has a higher home price on average, Atascadero has on average a lower home price.
SqFt and home price still have a regular price
regular status sale, compared to a foreclosure, has a 20k higher home price compared to a for closure sale.

these values are in line with what I would expect! More sound linear model, good thing we thought about our data!

## compare model fit

check out `summary(lm(homes_lm1))` in console
What is the R2 mean?? 84% of the variance in home price is explained by the predictor variables in this model (city, bed, bath, sqft, pricepersqft, etc all listed coefficients)l. However there are other varibles that we would need to be able to capure 100% varibale in price. To get a higher value we need additioal variable that don't explain that.

- adjusted R2 is what we just when we do multiple linear regression so we are looking at the adjusted r-squared.

check out `summary(lm(homes_lm2))` in console

here adjusted r-squared is ~53%

how do we weight trade off between model fit and conceptual understanding!

What is a quanititaive tool to ask the tradeoff being model fit and conceptual understanding

**AIC** - provides a sum comparison of balance between model fit and complexity.
- high fit and simple

Find the AIC value of each model

```{r}
AIC(homes_lm1)
AIC(homes_lm2) # lowers AIC val indicates a better fit beteen model fit and complexity. So then we would use the first model because it has a lower AIC
# but we did not like homes_lm1!
# there is a huge gap in model fit between R2 values of lm1 and lm2! maybe neither of these models are a good fit. back to drawing board for other potential varibales that exisit here.
```

## Try another permutaiton of this model that you think might make sense, then check out and compare the model fit, outputs and AIC values.

```{r}
homes_lm3 <- lm(Price ~ City + SqFt + Bedrooms + Status, data = home_sub)

summary(lm(homes_lm3))
```

```{r}
AIC(homes_lm1)
AIC(homes_lm2)
AIC(homes_lm3)
# All the modesl are wrong!!!
# Seems like bedrooms isnt good. Seeing a weird highly negative coefficient with bedrooms. 

```
```{r}
homes_lm4 <- lm(Price ~ City + SqFt + PricePerSqFt + Status, data = home_sub)

# price per sqft is not an independent of our dependent variable because its based on the actual home price sooo bad idea to include it in our model!

summary(lm(homes_lm4))
```

```{r}
modelsummary(homes_lm1) # if you use model summary to return model outputs of multiple models it wants you to feed it to it as a list

modelsummary(homes_lm1, homes_lm2, homes_lm3) # okay now you can compare based on what is still in the model or what has been removed from the model
```


## Start making predicitions with this model

SUe `brooms::augment()`

```{r}
homes_predicted <- augment(homes_lm1)
```

- fitted is what our models predicts it would be and it totally fails 


Use the `predict()` function to try out your model on new scenarios that you create

# MY UPDATE!!!

but how to merge changes in the main branch?